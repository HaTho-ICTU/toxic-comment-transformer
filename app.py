# app.py ‚Äî Streamlit Toxicity Checker (lazy load + debug)
import os, json, numpy as np, pandas as pd, torch
import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# ====== CONFIG ======
MODEL_DIR = "NLP_toxic"   # <-- S·ª¨A ƒê∆Ø·ªúNG D·∫™N N√ÄY (th∆∞ m·ª•c ch·ª©a config.json, pytorch_model.bin)
MAX_LEN   = 192

st.set_page_config(page_title="Toxicity Checker", page_icon="ü§ñ", layout="centered")
st.title("ü§ñ Toxicity Checker")
st.caption("Nh·∫≠p c√¢u, b·∫•m **Ki·ªÉm tra**. App s·∫Ω ph√¢n lo·∫°i Toxic/Non-Toxic. (Model load theo y√™u c·∫ßu)")

# Cho xem debug ·ªü sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Debug info")
    st.write("**Model dir:**", os.path.abspath(MODEL_DIR))
    st.write("**Files in model dir:**")
    if os.path.isdir(MODEL_DIR):
        st.code("\n".join(sorted(os.listdir(MODEL_DIR))), language="text")
    else:
        st.error("‚ùå MODEL_DIR kh√¥ng t·ªìn t·∫°i!")

# ====== SESSION STATE ======
if "loaded" not in st.session_state:
    st.session_state.loaded = False
if "tok" not in st.session_state:
    st.session_state.tok = None
if "model" not in st.session_state:
    st.session_state.model = None
if "device" not in st.session_state:
    st.session_state.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if "labels" not in st.session_state:
    st.session_state.labels = ["toxic"]     # s·∫Ω c·∫≠p nh·∫≠t sau khi load
if "thresholds" not in st.session_state:
    st.session_state.thresholds = np.array([0.5], dtype=float)
if "num_labels" not in st.session_state:
    st.session_state.num_labels = 1

def load_model_safely():
    """N·∫°p model & tokenizer, c√≥ th√¥ng b√°o l·ªói r√µ r√†ng."""
    try:
        tok = AutoTokenizer.from_pretrained(MODEL_DIR)
        model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(st.session_state.device).eval()
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ n·∫°p model/tokenizer t·ª´ `{MODEL_DIR}`.\n\n{e}")
        return

    # labels & thresholds
    default_labels = ["toxic","severe_toxic","obscene","threat","insult","identity_hate"]
    num_labels = int(model.config.num_labels)
    labels = default_labels[:num_labels] if num_labels > 1 else ["toxic"]

    thr_path = os.path.join(MODEL_DIR, "thresholds.json")
    if os.path.exists(thr_path):
        try:
            with open(thr_path, "r") as f:
                th_dict = json.load(f)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è ƒê·ªçc thresholds.json l·ªói, d√πng 0.5. Chi ti·∫øt: {e}")
            th_dict = {lab: 0.5 for lab in labels}
    else:
        st.info("‚ÑπÔ∏è Kh√¥ng th·∫•y thresholds.json, d√πng threshold = 0.5 cho t·∫•t c·∫£ nh√£n.")
        th_dict = {lab: 0.5 for lab in labels}
    thresholds = np.array([th_dict.get(l, 0.5) for l in labels], dtype=float)

    # set state
    st.session_state.tok = tok
    st.session_state.model = model
    st.session_state.labels = labels
    st.session_state.thresholds = thresholds
    st.session_state.num_labels = num_labels
    st.session_state.loaded = True
    st.success(f"‚úÖ Model loaded. Labels: {labels} | Thresholds: {thresholds.tolist()}")

@torch.no_grad()
def predict_one(text: str):
    tok = st.session_state.tok
    model = st.session_state.model
    device = st.session_state.device

    enc = tok([text], truncation=True, padding=True, max_length=MAX_LEN, return_tensors="pt")
    enc = {k: v.to(device) for k, v in enc.items()}
    logits = model(**enc).logits
    probs = torch.sigmoid(logits).cpu().numpy()[0]   # shape [L]
    return probs

# ====== FORM ======
with st.form("tox_form"):
    text = st.text_area("Nh·∫≠p c√¢u ti·∫øng Anh", height=130,
                        placeholder="e.g., I hate you. You are disgusting!")
    col1, col2 = st.columns(2)
    with col1:
        btn_load = st.form_submit_button("üöÄ Load model (n·∫øu ch∆∞a)")
    with col2:
        btn_check = st.form_submit_button("üîé Ki·ªÉm tra")

if btn_load:
    load_model_safely()

if btn_check:
    if not st.session_state.loaded:
        st.warning("Vui l√≤ng b·∫•m **Load model** tr∆∞·ªõc.")
    elif not text.strip():
        st.warning("Vui l√≤ng nh·∫≠p c√¢u.")
    else:
        # d·ª± ƒëo√°n
        probs = predict_one(text)
        labels = st.session_state.labels
        ths = st.session_state.thresholds
        preds = (probs >= ths).astype(int)

        if st.session_state.num_labels == 1:
            overall = bool(preds[0])
        else:
            overall = bool(preds.sum() > 0)

        # k·∫øt qu·∫£
        st.subheader("K·∫øt qu·∫£")
        if overall:
            st.markdown('<div style="background:#FEF2F2;color:#991B1B;border:1px solid #FECACA;padding:10px 14px;border-radius:12px;font-weight:600;">K·∫øt lu·∫≠n: TOXIC</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div style="background:#ECFDF5;color:#065F46;border:1px solid #A7F3D0;padding:10px 14px;border-radius:12px;font-weight:600;">K·∫øt lu·∫≠n: NON-TOXIC</div>', unsafe_allow_html=True)

        # b·∫£ng x√°c su·∫•t
        df = pd.DataFrame({"label": labels, "probability": probs})
        st.dataframe(df.style.format({"probability": "{:.3f}"}), use_container_width=True)
        st.bar_chart(df.set_index("label"))

        st.caption("B·∫°n c√≥ th·ªÉ th√™m file thresholds.json trong th∆∞ m·ª•c model ƒë·ªÉ t√πy ch·ªânh ng∆∞·ª°ng theo nh√£n.")

# ====== QUICK HELP ======
with st.expander("‚ùì Kh√¥ng th·∫•y g√¨ hi·ªán l√™n? Th·ª≠ ki·ªÉm tra nhanh"):
    st.markdown("""
1. Ch·∫°y ƒë√∫ng l·ªánh: `streamlit run app.py` (xem log ·ªü terminal c√≥ b√°o l·ªói kh√¥ng).
2. ƒê·∫£m b·∫£o `MODEL_DIR` l√† th∆∞ m·ª•c h·ª£p l·ªá, c√≥ `config.json`, `pytorch_model.bin`, `tokenizer.json`/`vocab.txt`, v.v.
3. N·∫øu d√πng Windows & tr√¨nh duy·ªát C·ªëc C·ªëc, th·ª≠ m·ªü b·∫±ng Chrome/Edge kh√°c ho·∫∑c t·∫Øt ad-block.
4. Kh√¥ng ƒë·ªÉ l·ªánh t·∫£i model qu√° n·∫∑ng ·ªü ƒë·∫ßu ch∆∞∆°ng tr√¨nh (b·∫£n n√†y ƒë√£ lazy load).
""")
